{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iwdkADHTsZRV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import psycopg2 as ps\n",
        "import sklearn.metrics as skm\n",
        "import sklearn.model_selection as sms\n",
        "import sklearn.tree as st\n",
        "import sklearn.neighbors as snn\n",
        "import sklearn.preprocessing as sp\n",
        "import sklearn.ensemble as se\n",
        "import numpy as np\n",
        "import pandas.io.sql as sqlio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ZCXMAp9KspZ-",
        "outputId": "7ba8562a-ce6d-4865-de6f-7e15a236b989"
      },
      "outputs": [],
      "source": [
        "conn = ps.connect( # Connect to Redshift Serverless Database\n",
        "    host='galaxy2-dw.169592149406.us-east-1.redshift-serverless.amazonaws.com',\n",
        "    port=5439,\n",
        "    database='dev',\n",
        "    user='evanf',\n",
        "    password='yayAtHa3'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LqiE_WtKvqUx"
      },
      "outputs": [],
      "source": [
        "query = 'SELECT deaths, star_bits, coins, difficulty, lives_found, avg_hits, bossIndex, prankIndex, enemy_rank, trap_rank, power_rank FROM diff_model'\n",
        "data = sqlio.read_sql_query(query, conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Q8IemFZ428rS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   deaths  star_bits  coins   difficulty  lives_found  avg_hits  bossindex  \\\n",
            "0       0         79     21  Easy-Medium            1       0.0        1.0   \n",
            "1       0        161     29  Easy-Medium            0       0.0        0.0   \n",
            "2       0          8      0       Expert            1       0.0        0.0   \n",
            "3       0         99      0  Medium-Hard            0       0.0        0.0   \n",
            "4       0         91      4  Medium-Hard            0       0.0        0.0   \n",
            "\n",
            "   prankindex  enemy_rank  trap_rank  power_rank  \n",
            "0         0.0        52.0       11.0        20.0  \n",
            "1         0.0        50.0       23.0        12.0  \n",
            "2         1.0       100.0       44.0        20.0  \n",
            "3         1.0        55.0       50.0         4.0  \n",
            "4         1.0        18.0       50.0        20.0  \n"
          ]
        }
      ],
      "source": [
        "print(data.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "XZgUR4Ge4bZ8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Easy       0.50      0.25      0.33         4\n",
            " Easy-Medium       0.25      0.33      0.29         3\n",
            "      Expert       0.00      0.00      0.00         1\n",
            "        Hard       0.33      0.25      0.29         8\n",
            "      Harder       0.00      0.00      0.00         2\n",
            "      Medium       0.33      0.57      0.42         7\n",
            " Medium-Hard       0.56      0.42      0.48        12\n",
            "\n",
            "    accuracy                           0.35        37\n",
            "   macro avg       0.28      0.26      0.26        37\n",
            "weighted avg       0.39      0.35      0.36        37\n",
            "\n",
            "[[1 0 0 0 0 2 1]\n",
            " [0 1 0 1 0 1 0]\n",
            " [0 0 0 0 0 1 0]\n",
            " [1 0 0 2 1 2 2]\n",
            " [0 0 0 0 0 1 1]\n",
            " [0 2 0 1 0 4 0]\n",
            " [0 1 0 2 3 1 5]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\evanf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\evanf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\evanf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "x = data[['deaths', 'avg_hits', 'bossindex', 'prankindex', 'enemy_rank', 'trap_rank', 'power_rank']]\n",
        "y = data['difficulty']\n",
        "\n",
        "x_train, x_test, y_train, y_test = sms.train_test_split(x, y, test_size = 0.3, random_state = 102)\n",
        "\n",
        "diff_dt = st.DecisionTreeClassifier(max_depth = 6) # Use a Decision Tree Classifier this time\n",
        "diff_dt.fit(x_train, y_train)\n",
        "difficulty_dt_pred = diff_dt.predict(x_test)\n",
        "\n",
        "print(skm.classification_report(y_test, difficulty_dt_pred)) # Find the results of the model\n",
        "print(skm.confusion_matrix(y_test, difficulty_dt_pred)) # Print the Confusion matrix of the model\n",
        "\n",
        "difficulty_rf = se.RandomForestClassifier(n_estimators = 300) # Use 300 trees\n",
        "difficulty_rf.fit(x_train, y_train)\n",
        "difficulty_rf_pred = difficulty_rf.predict(x_test)\n",
        "\n",
        "#print(skm.classification_report(y_test, difficulty_rf_pred)) # Find the results of the model\n",
        "#print(skm.confusion_matrix(y_test, difficulty_rf_pred)) # Print the Confusion matrix of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not very good results besides for medium-hard levels but when lives_found and major_sections are taken out the results are a little better and then even better when taking out coins and star bits\n",
        "Also see there are not a lot of data points for every difficulty to test so precision is 0 and accuracy is very low\n",
        "Maybe need to incorporate Mario Galaxy 1 data points we can have more data to build a better model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Easy       0.25      0.50      0.33         4\n",
            " Easy-Medium       0.50      0.33      0.40         3\n",
            "      Expert       0.25      1.00      0.40         1\n",
            "        Hard       0.50      0.12      0.20         8\n",
            "      Harder       0.00      0.00      0.00         2\n",
            "      Medium       0.44      0.57      0.50         7\n",
            " Medium-Hard       0.60      0.50      0.55        12\n",
            "\n",
            "    accuracy                           0.41        37\n",
            "   macro avg       0.36      0.43      0.34        37\n",
            "weighted avg       0.46      0.41      0.39        37\n",
            "\n",
            "[[2 0 0 0 0 1 1]\n",
            " [1 1 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 0]\n",
            " [2 0 2 1 1 0 2]\n",
            " [0 0 0 0 0 2 0]\n",
            " [1 1 0 0 0 4 1]\n",
            " [2 0 0 1 1 2 6]]\n",
            "0.40540540540540543\n"
          ]
        }
      ],
      "source": [
        "# Try using KNN and see if results are improved --> they are vastly improved but still not great, need more data points\n",
        "\n",
        "# First we need to scale the data to be able to calculate distance between points\n",
        "scaler = sp.StandardScaler()\n",
        "scaler.fit(x)\n",
        "scaled_diff = scaler.transform(x)\n",
        "X_scaled = pd.DataFrame(scaled_diff, columns = x.columns)\n",
        "\n",
        "# Now train_test_split the scaled data then fit the model\n",
        "X_trains, X_tests, y_trains, y_tests = sms.train_test_split(X_scaled, y, test_size = 0.3, random_state = 102)\n",
        "diff_knn = snn.KNeighborsClassifier(n_neighbors = 8) # Use a value of 8 for K for best results\n",
        "\n",
        "diff_knn.fit(X_trains, y_trains)\n",
        "knn_pred = diff_knn.predict(X_tests)\n",
        "\n",
        "print(skm.classification_report(y_tests, knn_pred)) # Print the report for KNN\n",
        "print(skm.confusion_matrix(y_tests, knn_pred)) # Print the Confusion matrix for KNN and compare it to tree methods\n",
        "\n",
        "print(skm.accuracy_score(y_test, knn_pred)) # 0/very low precision and accuracy for harder and expert difficulties because of lack of data points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Easy       0.00      0.00      0.00         1\n",
            " Easy-Medium       0.00      0.00      0.00         2\n",
            "        Hard       0.50      0.14      0.22         7\n",
            "      Medium       0.33      0.15      0.21        13\n",
            " Medium-Hard       0.33      0.56      0.42         9\n",
            "\n",
            "    accuracy                           0.25        32\n",
            "   macro avg       0.23      0.17      0.17        32\n",
            "weighted avg       0.34      0.25      0.25        32\n",
            "\n",
            "[[0 1 0 0 0]\n",
            " [0 0 0 1 1]\n",
            " [1 2 1 1 2]\n",
            " [2 1 1 2 7]\n",
            " [1 1 0 2 5]]\n"
          ]
        }
      ],
      "source": [
        "# Use KNN but this time keep out Expert, Harder --> results are worse\n",
        "x = data[data.difficulty != 'Harder']\n",
        "x = x[x.difficulty != 'Expert']\n",
        "x_mod = x[['deaths', 'avg_hits', 'bossindex', 'prankindex', 'enemy_rank', 'trap_rank', 'power_rank']]\n",
        "y = x['difficulty']\n",
        "\n",
        "# First we need to scale the data to be able to calculate distance between points\n",
        "scaler = sp.StandardScaler()\n",
        "scaler.fit(x_mod)\n",
        "scaled_diff = scaler.transform(x_mod)\n",
        "X_scaled = pd.DataFrame(scaled_diff, columns = x_mod.columns)\n",
        "\n",
        "# Now train_test_split the scaled data then fit the model\n",
        "X_trains, X_tests, y_trains, y_tests = sms.train_test_split(X_scaled, y, test_size = 0.3, random_state = 102)\n",
        "diff_knn = snn.KNeighborsClassifier(n_neighbors = 8) # Use a value of 8 for K for best results\n",
        "\n",
        "diff_knn.fit(X_trains, y_trains)\n",
        "knn_pred = diff_knn.predict(X_tests)\n",
        "\n",
        "print(skm.classification_report(y_tests, knn_pred)) # Print the report for KNN\n",
        "print(skm.confusion_matrix(y_tests, knn_pred)) # Print the Confusion matrix for KNN and compare it to tree methods"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
